# Classifiaction-Clustering Evaluation System

**A Full-Stack End-to-End Machine Learning Evaluation Platform**

---

## ðŸ“ Overview
This system is a comprehensive analytical tool designed to automate the lifecycle of Machine Learning models. It bridges the gap between raw data and actionable insights by providing a structured environment for **Classification benchmarking**, **Unsupervised Clustering**, and **Deep Learning-based feature engineering**.

The platform is designed for reproducibility, allowing users to upload datasets, tune hyperparameters via a React interface, and receive detailed statistical evaluations and automated conclusions.

---

## ðŸš€ Key Features

### 1. Classification & Statistical Benchmarking
* **Automated Evaluation:** Trains multiple models including `Random Forest`, `SVM`, `Logistic Regression`, `LDA`, and `Naive Bayes`.
* **Validation Rigor:** Utilizes **Stratified K-Fold Cross-Validation** to ensure metrics like ROC-AUC and F1-Score are statistically sound.
* **Intelligent Conclusion:** Analyzes results to automatically identify and recommend the optimal model for the specific dataset based on Mean and STD of performance.

### 2. Clustering & Representation Learning
* **Stacked Autoencoders (SAE):** A Deep Learning pipeline built with **Keras** that compresses high-dimensional data (including image datasets) into a latent feature space.
* **Advanced Clustering:** Executes `K-Means` and `DBSCAN` on the optimized feature set.
* **Performance Metrics:** Computes **Silhouette** and **Davies-Bouldin** scores for internal validation.

### 3. Dynamic User Interface
* **Live Hyperparameter Tuning:** Dedicated forms to adjust algorithm parameters (C, eps, n_clusters, etc.) on-the-fly.
* **Visual Reports:** Automatically generates **Confusion Matrices** and performance heatmaps using Seaborn and Matplotlib.
* **Result Export:** Packages all metrics and visualizations into a downloadable `.zip` file.

---

## ðŸ“ Project Structure
```text
â”œâ”€â”€ backend/                        # Python Flask Backend
â”‚   â”œâ”€â”€ clustering/                 # Unsupervised Learning Modules
â”‚   â”‚   â”œâ”€â”€ clusteringOutput.py     # Results generation logic
â”‚   â”‚   â”œâ”€â”€ dataLoader.py           # Dataset ingestion for clustering
â”‚   â”‚   â”œâ”€â”€ evaluation.py           # Clustering metrics (Silhouette, etc.)
â”‚   â”‚   â”œâ”€â”€ pipeline.py             # Execution orchestration
â”‚   â”‚   â”œâ”€â”€ preprocessing.py        # Data cleaning & scaling
â”‚   â”‚   â”œâ”€â”€ stackedAutoEncoder.py   # SAE for dimensionality reduction
â”‚   â”‚   â””â”€â”€ visualization.py        # Cluster plotting & charts
â”‚   â”œâ”€â”€ ml_pipeline/                # Classification Modules
â”‚   â”‚   â”œâ”€â”€ conclusion.py           # Model comparison & best-fit selection
â”‚   â”‚   â”œâ”€â”€ create_matrix.py        # Confusion Matrix generation
â”‚   â”‚   â”œâ”€â”€ data_loader.py          # Dataset ingestion for classification
â”‚   â”‚   â”œâ”€â”€ evaluation.py           # Stratified K-Fold cross-validation
â”‚   â”‚   â”œâ”€â”€ feature_selection.py    # Dimensionality reduction for classifiers
â”‚   â”‚   â””â”€â”€ preprocessing.py        # Data cleaning & encoding
â”‚   â”œâ”€â”€ services/                   # Orchestration Layer
â”‚   â”‚   â”œâ”€â”€ config_service.py       # Global parameter management
â”‚   â”‚   â”œâ”€â”€ outputAverages.py       # Multi-run metric averaging
â”‚   â”‚   â””â”€â”€ pipeline_service.py     # Main service handler
â”‚   â”œâ”€â”€ utils/                      # Helper Modules
â”‚   â”‚   â””â”€â”€ file_utils.py           # File system & path management
â”‚   â”œâ”€â”€ app.py                      # Flask API Entry Point
â”‚   â”œâ”€â”€ config.py                   # Server & ML environment configuration
â”‚   â””â”€â”€ requirements.txt            # Python dependencies
â”‚
â”œâ”€â”€ frontend/                       # React Vite Application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ component/              # UI Components
â”‚   â”‚   â”‚   â”œâ”€â”€ HomePage.jsx        # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ classification.jsx  # Classification dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ clustering.jsx      # Clustering dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ ClusteringTuning.jsx # Specialized clustering parameters
â”‚   â”‚   â”‚   â””â”€â”€ tuning.jsx          # General hyperparameter UI
â”‚   â”‚   â”œâ”€â”€ style/                  # Modular CSS Styling
â”‚   â”‚   â”‚   â”œâ”€â”€ HomePage.css
â”‚   â”‚   â”‚   â”œâ”€â”€ classification.css
â”‚   â”‚   â”‚   â”œâ”€â”€ clustering.css
â”‚   â”‚   â”‚   â””â”€â”€ tuning.css
â”‚   â”‚   â”œâ”€â”€ App.jsx                 # Application Routing
â”‚   â”‚   â”œâ”€â”€ main.jsx                # React DOM entry point
â”‚   â”‚   â””â”€â”€ index.css               # Global styles
â”‚   â”œâ”€â”€ package.json                # Frontend dependencies
â”‚   â””â”€â”€ vite.config.js              # Vite build configuration
â”‚
â””â”€â”€ .gitignore                      # Global exclusion rules
```
## ðŸ› ï¸ Installation & Setup

### 1. Prerequisites
Before you begin, ensure you have the following installed:
* **Python 3.8+**
* **Node.js & npm**
* **Virtual Environment** (Highly recommended to avoid dependency conflicts)

### 2. Backend Installation
Navigate to the project root directory and follow these steps to set up the Python environment:



```bash
# 1. Create a virtual environment
python -m venv venv

# 2. Activate the virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# 3. Install required Python dependencies
pip install -r requirements.txt

# 4. Start the Flask backend server
python app.py
```

### 3. Frontend Installation
Open a new terminal window, navigate to the `frontend` directory, and launch the React application:



```bash
# 1. Navigate to the frontend folder
cd frontend

# 2. Install Node.js packages
npm install

# 3. Start the Vite development server
npm run dev
```
## ðŸ“Š Evaluation Metrics Computed

The platform performs a deep statistical analysis for every model executed. The following metrics are automatically calculated and presented in the final reports:

| Metric | Purpose |
| :--- | :--- |
| **Accuracy** | Measures the proportion of total correct predictions (both TP and TN) out of all instances. |
| **Precision** | Indicates the accuracy of positive predictions; the ratio of TP to the total predicted positives. |
| **Recall** | Measures the ability of the model to find all relevant cases (TP) within the actual positive class. |
| **ROC-AUC** | Measures the model's ability to distinguish between classes across all probability thresholds. |
| **F1-Score** | Provides the harmonic mean of Precision and Recall, ideal for evaluating imbalanced datasets. |
| **Confusion Matrix** | Provides a visual breakdown of True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN). |
| **Silhouette Score** | Validates clustering quality by measuring how well-separated and cohesive the clusters are (higher is better). |
| **Davies-Bouldin Index** | Evaluates clustering by the average similarity between each cluster and its most similar one (lower is better). |

---


## ðŸ›¡ï¸ Security & Best Practices

Data integrity and system security are core components of this pipeline:

* **Secure File Handling:** The backend utilizes `secure_filename` for all file uploads to prevent **Directory Traversal** attacks.
* **Credential Management:** Sensitive API keys (such as Kaggle credentials) are managed strictly via environment variables. 
    > **Note:** Ensure your `.env` file is included in your `.gitignore` to prevent accidental credential exposure.
* **Session Isolation:** Evaluation results and temporary plots are isolated using unique UUIDs to ensure multi-user stability.
